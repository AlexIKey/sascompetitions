{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение SAS\n",
    "\n",
    "## Прогнозирование вероятности невозврата кредита\n",
    "\n",
    "### Данные ООО «Хоум Кредит энд Финанс Банк» \n",
    "\n",
    "2017, Александр Дьяконов\n",
    "\n",
    "https://alexanderdyakonov.wordpress.com/\n",
    "\n",
    "\n",
    "## Описание метода\n",
    "\n",
    "* предобработка данных\n",
    "* подготовка признаковых матриц\n",
    " * одна матрица - статистики по всем кредитам (среднее, максимум, минимум и т.д. исходных признаков)\n",
    " * вторая - аналогично, но перед вычислением статистик информация по одинаковым кредитам схлопывается\n",
    "* ответ - среднее модели на этих двух признаковых пространствах\n",
    "* модель - среднее 4х xgb и 4х lgb (бустинги над деревьями разных реализаций)\n",
    "* модель запускается 15 раз, ответ получается усреднением\n",
    "\n",
    "**Время работы** скрипта: 36 минут (вычисление признаков) + 4.2 часа (обучение модели)\n",
    "\n",
    "**Важно**: код для Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# подгружаем все нужные пакеты\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline\n",
    "plt.style.use('seaborn-dark')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размеры (1787571, 34) (1665298, 33)\n",
      "объектов в обучении 135155\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# обучение\n",
    "data_train = pd.read_csv('train.csv')\n",
    "# контроль\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "print ('размеры', data_train.shape, data_test.shape)\n",
    "\n",
    "# целевой вектор\n",
    "data = data_train.groupby('ID')['DEF'].mean().reset_index()\n",
    "y = data.DEF.values\n",
    "del data_train['DEF']\n",
    "\n",
    "print ('объектов в обучении', len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Порождение признакового пространства\n",
    "\n",
    "сначала перечень всех используемых функций..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3452869, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# всё в одну таблицу\n",
    "data_all = pd.concat([data_train, data_test])\n",
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_time_features(data):\n",
    "    \"\"\"\n",
    "    сделать временные признаки\n",
    "    \"\"\"\n",
    "\n",
    "    data['SK_DATE_DECISION'] = pd.to_datetime(data['SK_DATE_DECISION'], format='%Y%m%d')\n",
    "    data['DTIME_CREDIT'] = pd.to_datetime(data['DTIME_CREDIT'], format='%d.%m.%Y')\n",
    "    data['DTIME_CREDIT_ENDDATE'] = pd.to_datetime(data['DTIME_CREDIT_ENDDATE'], format='%d.%m.%Y')\n",
    "    data['DTIME_CREDIT_ENDDATE_FACT'] = pd.to_datetime(data['DTIME_CREDIT_ENDDATE_FACT'], format='%d.%m.%Y')\n",
    "    data['DTIME_CREDIT_UPDATE'] = pd.to_datetime(data['DTIME_CREDIT_UPDATE'], format='%d.%m.%Y')\n",
    "    \n",
    "    data['SK_DATE_DECISION_dayofweek'] = data['SK_DATE_DECISION'].dt.dayofweek\n",
    "    data['SK_DATE_DECISION_day'] = data['SK_DATE_DECISION'].dt.day\n",
    "    \n",
    "    \n",
    "    data['DTIME_CREDIT_dayofweek'] = data['DTIME_CREDIT'].dt.dayofweek\n",
    "    data['DTIME_CREDIT_ENDDATE_FACT_dayofweek'] = data['DTIME_CREDIT_ENDDATE_FACT'].dt.dayofweek\n",
    "    data['DTIME_CREDIT_UPDATE_dayofweek'] = data['DTIME_CREDIT_UPDATE'].dt.dayofweek\n",
    "    \n",
    "    \n",
    "    # на какой срок\n",
    "    data['DELTA_CREDIT'] = (data['DTIME_CREDIT_ENDDATE'] - data['DTIME_CREDIT']).astype(\"timedelta64[D]\")\n",
    "    data['DELTA_CREDIT'] = data['DELTA_CREDIT'].fillna(2158.9)\n",
    "    data['DELTA_CREDIT2'] = (data['DTIME_CREDIT_ENDDATE_FACT'] - data['DTIME_CREDIT']).astype(\"timedelta64[D]\")\n",
    "    data['DELTA_CREDIT2'] = data['DELTA_CREDIT2'].fillna(410.5)\n",
    "    # взять их отношения\n",
    "    data['DELTA_ENDS'] = (data['DTIME_CREDIT_ENDDATE'] - data['DTIME_CREDIT_ENDDATE_FACT']).astype(\"timedelta64[D]\")\n",
    "    data['DELTA_ENDS'] = data['DELTA_ENDS'].fillna(600.8)\n",
    "    \n",
    "    \n",
    "    data['DIV_DELTAS'] = (data['DELTA_CREDIT2'] + 0.0) / (data['DELTA_CREDIT'].abs() + 0.1)\n",
    "    \n",
    "    # сколько дней назад открыт кредит\n",
    "    data['DTIME_CREDIT']  = (data['SK_DATE_DECISION'] - data['DTIME_CREDIT'] ).astype(\"timedelta64[D]\") # .astype(int)\n",
    "    data['DTIME_CREDIT_ENDDATE'] = (data['SK_DATE_DECISION'] - data['DTIME_CREDIT_ENDDATE'] ).astype(\"timedelta64[D]\")\n",
    "    \n",
    "    # +\n",
    "    data['null_in_DTIME_CREDIT_ENDDATE'] = data['DTIME_CREDIT_ENDDATE'].isnull() + 0\n",
    "    data['DTIME_CREDIT_ENDDATE'] = data['DTIME_CREDIT_ENDDATE'].fillna(-823)\n",
    "    \n",
    "    data['DTIME_CREDIT_ENDDATE_FACT'] = (data['SK_DATE_DECISION'] - data['DTIME_CREDIT_ENDDATE_FACT'] ).astype(\"timedelta64[D]\")\n",
    "    data['null_in_DTIME_CREDIT_ENDDATE_FACT'] = data['DTIME_CREDIT_ENDDATE_FACT'].isnull() + 0\n",
    "    data['DTIME_CREDIT_ENDDATE_FACT'] = data['DTIME_CREDIT_ENDDATE_FACT'].fillna(532)    \n",
    "    \n",
    "    \n",
    "    # обновление в источнике\n",
    "    data['DTIME_CREDIT_UPDATE'] = (data['SK_DATE_DECISION'] - data['DTIME_CREDIT_UPDATE'] ).astype(\"timedelta64[D]\")\n",
    "    \n",
    "    tm = data['SK_DATE_DECISION'].values\n",
    "    \n",
    "    ##########del data['SK_DATE_DECISION'] # ОСТАВИТЬ\n",
    "\n",
    "    \n",
    "    return (data, tm)\n",
    "\n",
    "\n",
    "def make_str_features(data):\n",
    "    \"\"\"\n",
    "    перекодировать строковые признаки\n",
    "    \"\"\"    \n",
    "    \n",
    "    data['CREDIT_CURRENCY'] = data['CREDIT_CURRENCY'].map({'rur': 0, 'usd': 1, 'eur': 2, 'chf': 2})\n",
    "    \n",
    "    data['CREDIT_FACILITY'] = data['CREDIT_FACILITY'].fillna(-1.0).astype(int)\n",
    "    \n",
    "    data['CREDIT_TYPE'] = data['CREDIT_TYPE'].map({0: 0,\n",
    "                                                   1: 1, #  кредит на автомобиль\n",
    "                                                   2: 0,\n",
    "                                                   3: 3, # ипотека\n",
    "                                                   4: 4, # кредитная карта\n",
    "                                                   5: 5, # потребительский кредит\n",
    "                                                   6: 0,\n",
    "                                                   7: 0,\n",
    "                                                   8: 0,\n",
    "                                                   9: 0,\n",
    "                                                   10: 0,\n",
    "                                                   11: 0,\n",
    "                                                   12: 0,\n",
    "                                                   13: 0,\n",
    "                                                   14: 0,\n",
    "                                                   15: 0,\n",
    "                                                   16: 0,\n",
    "                                                   17: 0,\n",
    "                                                   18: 0,\n",
    "                                                   19: 19, # микрозайм\n",
    "                                                   90: 0,\n",
    "                                                   99: 0\n",
    "                                                  })\n",
    "    \n",
    "    data['DOLG'] = (data['AMT_CREDIT_SUM_DEBT'] + 0.0) / (data['AMT_CREDIT_SUM'].abs() + 1.0)\n",
    "\n",
    "    return (data)\n",
    "\n",
    "def make_null_features(data):\n",
    "    \"\"\"\n",
    "    заменить пропуски\n",
    "    \"\"\"\n",
    "    # в make_str_features data['CREDIT_FACILITY'] = data['CREDIT_FACILITY'].fillna(-1) # [ nan,   9.,   0.,   2.,   1.] мелк. кат\n",
    "    data['AMT_CREDIT_SUM'] = data['AMT_CREDIT_SUM'].fillna(85202.1) # слишком мало значений\n",
    "    data['null_in_AMT_CREDIT_SUM_DEBT'] = data.AMT_CREDIT_SUM_DEBT.isnull() + 0\n",
    "    data['AMT_CREDIT_SUM_DEBT'] = data['AMT_CREDIT_SUM_DEBT'].fillna(26895.1) # но тут едет значение\n",
    "    data['null_in_AMT_CREDIT_SUM_LIMIT'] = data.AMT_CREDIT_SUM_LIMIT.isnull() + 0\n",
    "    data['AMT_CREDIT_SUM_LIMIT'] = data['AMT_CREDIT_SUM_LIMIT'].fillna(1558.7) # но тут едет значение\n",
    "    data['null_in_AMT_ANNUITY'] = data.AMT_ANNUITY.isnull() + 0\n",
    "    data['AMT_ANNUITY'] = data['AMT_ANNUITY'].fillna(2882.1) # но тут едет значение\n",
    "    \n",
    "    data['null_in_AMT_CREDIT_MAX_OVERDUE'] = data.AMT_CREDIT_MAX_OVERDUE.isnull() + 0\n",
    "    data['AMT_CREDIT_MAX_OVERDUE'] = data['AMT_CREDIT_MAX_OVERDUE'].fillna(751.7) \n",
    "    \n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_features = ['AMT_REQ_SOURCE_HOUR',\n",
    "                 'AMT_REQ_SOURCE_DAY',\n",
    "                 'AMT_REQ_SOURCE_WEEK',\n",
    "                 'AMT_REQ_SOURCE_MON',\n",
    "                 'AMT_REQ_SOURCE_QRT',\n",
    "                 'AMT_REQ_SOURCE_YEAR',\n",
    "                 'SK_DATE_DECISION_dayofweek',\n",
    "                 'SK_DATE_DECISION_day',\n",
    "                 ### 'SK_DATE_DECISION' # NEW!!!\n",
    "                ]\n",
    "\n",
    "\n",
    "def make_user_features(data, user_features):\n",
    "    \"\"\"\n",
    "    признаки, которые зависят только от пользователя\n",
    "    \"\"\"\n",
    "    tmp = data[ ['ID'] + user_features]\n",
    "    tmp.fillna(-999, inplace=True) # можно не делать...\n",
    "    tmp = tmp.groupby('ID').last() # .mean()\n",
    "    tmp.reset_index(inplace=True)\n",
    "    return (tmp)\n",
    "\n",
    "bin_features = ['CREDIT_SUM_TYPE', # бинарный\n",
    "                'null_in_AMT_CREDIT_SUM_DEBT',\n",
    "                'null_in_AMT_CREDIT_SUM_LIMIT',\n",
    "                'null_in_AMT_ANNUITY',\n",
    "                'null_in_DTIME_CREDIT_ENDDATE',\n",
    "                'null_in_DTIME_CREDIT_ENDDATE_FACT'\n",
    "               ]\n",
    "\n",
    "def make_bin_features(df, names):\n",
    "    \"\"\"\n",
    "    бинарные признаки -> средние значения\n",
    "    \"\"\"\n",
    "    tmp = df.groupby('ID')[names].mean().fillna(-1)\n",
    "    tmp.columns = ['mean__' + str(x) for x in tmp.columns]\n",
    "    tmp = tmp.reset_index()\n",
    "    return (tmp)\n",
    "\n",
    "cat_features = ['NUM_SOURCE', # источник\n",
    "                'CREDIT_TYPE', # тип договора\n",
    "                'CREDIT_ACTIVE', # статус\n",
    "                'CREDIT_CURRENCY', # валюта\n",
    "                'CREDIT_FACILITY', # ???\n",
    "                'DTIME_CREDIT_dayofweek',\n",
    "                'DTIME_CREDIT_ENDDATE_FACT_dayofweek',\n",
    "                'DTIME_CREDIT_UPDATE_dayofweek'\n",
    "               ]\n",
    "\n",
    "def make_cat_feature(df, name, normalize=True):\n",
    "    \"\"\"\n",
    "    один категориальный признак\n",
    "    в матрицу числа вхождений\n",
    "    \"\"\"\n",
    "    tmp = df.groupby(['ID', name]).size().unstack().fillna(0)\n",
    "    tmp.columns = [name + '__' + str(x) for x in tmp.columns]\n",
    "    if normalize:\n",
    "        tmp = tmp.div(tmp.sum(axis=1), axis=0)\n",
    "        tmp.fillna(0.0)\n",
    "    tmp = tmp.reset_index()\n",
    "    return (tmp)\n",
    "\n",
    "def make_cat_features(df, cat_features, normalize=True):\n",
    "    \"\"\"\n",
    "    обработать все категориальные признаки\n",
    "    \"\"\"\n",
    "    tmp = df.groupby('ID').size().reset_index()\n",
    "    tmp.columns = ['ID', 'SIZE']\n",
    "    for name in cat_features:\n",
    "        tmp2 = make_cat_feature(df, name, normalize)\n",
    "        print ('category', name, tmp2.shape)\n",
    "        tmp = tmp.merge(tmp2, how='left', on='ID')\n",
    "        \n",
    "    return (tmp)\n",
    "\n",
    "log_features = ['LOG_CREDIT_DAY_OVERDUE', # текущая просроченная задолженность, дни\n",
    "                'LOG_CNT_CREDIT_PROLONG', # число пролонгаций кредита\n",
    "                'LOG_AMT_CREDIT_SUM', # сумма кредита (LOG ????)\n",
    "                'LOG_AMT_CREDIT_SUM_DEBT', # сумма оставшегося долга (DIV ????)\n",
    "                'LOG_AMT_CREDIT_SUM_LIMIT', # лимит (для карт)\n",
    "                'LOG_AMT_CREDIT_SUM_OVERDUE', # текущая просроченная задолженность, сумма\n",
    "                'LOG_AMT_CREDIT_MAX_OVERDUE', # макс задолженность\n",
    "                'LOG_CREDIT_DELAY5',\n",
    "                'LOG_CREDIT_DELAY30',\n",
    "                'LOG_CREDIT_DELAY60',\n",
    "                'LOG_CREDIT_DELAY90',\n",
    "                'LOG_CREDIT_DELAY_MORE',\n",
    "                'LOG_AMT_ANNUITY',\n",
    "                'LOG_DOLG']\n",
    "\n",
    "def make_logs(df, log_features):\n",
    "    \"\"\"\n",
    "    прологарифмировать признаки\n",
    "    \"\"\"\n",
    "    for name in log_features:\n",
    "        df[name] = np.log(df[name[4:]].abs() + 1) # 'LOG_' +\n",
    "    return df\n",
    "\n",
    "real_features = ['CREDIT_DAY_OVERDUE', # текущая просроченная задолженность, дни\n",
    "                 'CNT_CREDIT_PROLONG', # число пролонгаций кредита\n",
    "                 'AMT_CREDIT_SUM', # сумма кредита (LOG ????)\n",
    "                 'AMT_CREDIT_SUM_DEBT', # сумма оставшегося долга (DIV ????)\n",
    "                 'AMT_CREDIT_SUM_LIMIT', # лимит (для карт)\n",
    "                 'AMT_CREDIT_SUM_OVERDUE', # текущая просроченная задолженность, сумма\n",
    "                 'AMT_CREDIT_MAX_OVERDUE', # макс задолженность\n",
    "                 'CREDIT_DELAY5',\n",
    "                 'CREDIT_DELAY30',\n",
    "                 'CREDIT_DELAY60',\n",
    "                 'CREDIT_DELAY90',\n",
    "                 'CREDIT_DELAY_MORE',\n",
    "                 'AMT_ANNUITY',\n",
    "                 'DOLG']\n",
    "\n",
    "realtime_features = ['DELTA_CREDIT',\n",
    "                     'DELTA_CREDIT2',\n",
    "                     'DELTA_ENDS',\n",
    "                     'DTIME_CREDIT',\n",
    "                     'DTIME_CREDIT_ENDDATE',\n",
    "                     'DTIME_CREDIT_ENDDATE_FACT',\n",
    "                     'DTIME_CREDIT_UPDATE',\n",
    "                     'DIV_DELTAS']\n",
    "\n",
    "\n",
    "    \n",
    "def make_real_feature(df, name):\n",
    "    \"\"\"\n",
    "    вычисление разных статистик\n",
    "    \"\"\"\n",
    "    tmp = df.groupby('ID')[name].agg({mean, max, min, median, sum, var}).fillna(-1)\n",
    "    tmp.columns = [name + '__' + str(x) for x in tmp.columns]\n",
    "    tmp = tmp.reset_index()\n",
    "    return (tmp)\n",
    "\n",
    "def make_real_features(df, real_features):\n",
    "    \"\"\"\n",
    "    обработать все вещественные признаки\n",
    "    \"\"\"\n",
    "    tmp = df.groupby('ID').size().reset_index()\n",
    "    tmp.columns = ['ID', 'SIZE']\n",
    "    for name in real_features:\n",
    "        tmp2 = make_real_feature(df, name,)\n",
    "        print ('real', name, tmp2.shape)\n",
    "        tmp = tmp.merge(tmp2, how='left', on='ID')\n",
    "    del tmp['SIZE']\n",
    "    return (tmp)\n",
    "\n",
    "def count_in_str(x, ch, deg=1):\n",
    "    \"\"\"\n",
    "    веса для анализа строки\n",
    "    \"\"\"\n",
    "    return (sum((1./t ** deg for t, c in enumerate(x, start=1) if c==ch)) / (0.01 + sum((1./t ** deg for t in range(1, 1+len(x))))))\n",
    "\n",
    "txt_features = ['TXT_0', 'TXT_1', 'TXT_2', 'TXT_3', 'TXT_4', 'TXT_5', 'TXT_X', 'TXT_C']\n",
    "txt_features2 = ['TXTn_0', 'TXTn_1', 'TXTn_2', 'TXTn_3', 'TXTn_4', 'TXTn_5', 'TXTn_X', 'TXTn_C']\n",
    "txt_features0 = ['TXT_L']\n",
    "\n",
    "txt_features3 = ['BF_0', 'BF_1', 'BF_2', 'BF_3', 'BF_4', 'BF_5', 'BF_X', 'BF_C',\n",
    "                 'BF2_0', 'BF2_1', 'BF2_2', 'BF2_3', 'BF2_4', 'BF2_5', 'BF2_X', 'BF2_C',\n",
    "                 'BF0_0', 'BF0_1', 'BF0_2', 'BF0_3', 'BF0_4', 'BF0_5', 'BF0_X', 'BF0_C'\n",
    "                ]\n",
    "\n",
    "\n",
    "def make_txt(tt):\n",
    "    \"\"\"\n",
    "    сделать признаки по\n",
    "    платёжной строке\n",
    "    \"\"\"\n",
    "    \n",
    "    dct = {'0':0, '1':1, '2':2, '3':3, '4':4, '5':5, 'X':6, 'C':7}\n",
    "    \n",
    "    tt['TEXT_PAYMENT_DISCIPLINE'].fillna('', inplace=True)\n",
    "    \n",
    "    chs = ['0', '1', '2', '3', '4', '5', 'X', 'C']\n",
    "    for ch in chs:\n",
    "        tt['TXT_' + ch] = tt['TEXT_PAYMENT_DISCIPLINE'].map(lambda x: x.count(ch))\n",
    "        tt['BF_' + ch] = tt['TEXT_PAYMENT_DISCIPLINE'].map(lambda x: count_in_str(x, ch, 1))\n",
    "        tt['BF2_' + ch] = tt['TEXT_PAYMENT_DISCIPLINE'].map(lambda x: count_in_str(x, ch, 2))\n",
    "        tt['BF0_' + ch] = tt['TEXT_PAYMENT_DISCIPLINE'].map(lambda x: count_in_str(x, ch, 0.5))\n",
    "        print (ch, 'ждите...')\n",
    "        \n",
    "    \n",
    "    tt['TXT_L'] = tt['TEXT_PAYMENT_DISCIPLINE'].map(len)\n",
    "    \n",
    "    tt['TPD0'] = data_all['TEXT_PAYMENT_DISCIPLINE'].map(lambda x: dct[x[0]] if len(x)>0 else -1)\n",
    "        \n",
    "    tt[txt_features2] = tt[txt_features].div(tt[txt_features].abs().sum(axis=1) + 0.001, axis=0)\n",
    "    \n",
    "    \n",
    "    return (tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обработка признаков\n",
    "\n",
    "* перекодировка\n",
    "* обработка строк\n",
    "* заполнение пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "X\n",
      "C\n",
      "время:  2065.846471309662\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "time_ = time()\n",
    "\n",
    "data_all, time_all = make_time_features(data_all)\n",
    "data_all = make_str_features(data_all)\n",
    "data_all = make_null_features(data_all)\n",
    "### data_all = make_logs(data_all, log_features)\n",
    "data_all = make_txt(data_all)\n",
    "\n",
    "print ('время: ', time() - time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# схлопнуть информацию об одинаковых кредитах...\n",
    "data_pre = data_all.drop(['SK_DATE_DECISION', 'TEXT_PAYMENT_DISCIPLINE'], axis=1).groupby(['ID', 'CREDIT_CURRENCY', 'DTIME_CREDIT','CREDIT_TYPE']).max().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сформировать признаковую матрицу\n",
    "\n",
    "Строим 2 матрицы\n",
    "\n",
    "* по всей информации\n",
    "* по \"схлопнутой\" из *data_pre*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_feature_matrix(train_fm, ids):\n",
    "    \"\"\"\n",
    "    Создать признаковую матрицу\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame({'ID': ids})\n",
    "    \n",
    "    for t, tmp in enumerate(train_fm):\n",
    "        tmp.columns = [str(t) + 'c_' + x if x!='ID' else 'ID' for x in tmp.columns]\n",
    "        data = data.merge(tmp, on='ID', how='left') #, inplace='True')\n",
    "    \n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category NUM_SOURCE (255722, 5)\n",
      "category CREDIT_TYPE (255722, 7)\n",
      "category CREDIT_ACTIVE (255722, 5)\n",
      "category CREDIT_CURRENCY (255722, 4)\n",
      "category CREDIT_FACILITY (255722, 6)\n",
      "category DTIME_CREDIT_dayofweek (255722, 8)\n",
      "category DTIME_CREDIT_ENDDATE_FACT_dayofweek (238467, 8)\n",
      "category DTIME_CREDIT_UPDATE_dayofweek (255722, 8)\n",
      "category TPD0 (255722, 10)\n",
      "real CREDIT_DAY_OVERDUE (255722, 7)\n",
      "real CNT_CREDIT_PROLONG (255722, 7)\n",
      "real AMT_CREDIT_SUM (255722, 7)\n",
      "real AMT_CREDIT_SUM_DEBT (255722, 7)\n",
      "real AMT_CREDIT_SUM_LIMIT (255722, 7)\n",
      "real AMT_CREDIT_SUM_OVERDUE (255722, 7)\n",
      "real AMT_CREDIT_MAX_OVERDUE (255722, 7)\n",
      "real CREDIT_DELAY5 (255722, 7)\n",
      "real CREDIT_DELAY30 (255722, 7)\n",
      "real CREDIT_DELAY60 (255722, 7)\n",
      "real CREDIT_DELAY90 (255722, 7)\n",
      "real CREDIT_DELAY_MORE (255722, 7)\n",
      "real AMT_ANNUITY (255722, 7)\n",
      "real DOLG (255722, 7)\n",
      "real DELTA_CREDIT (255722, 7)\n",
      "real DELTA_CREDIT2 (255722, 7)\n",
      "real DELTA_ENDS (255722, 7)\n",
      "real DTIME_CREDIT (255722, 7)\n",
      "real DTIME_CREDIT_ENDDATE (255722, 7)\n",
      "real DTIME_CREDIT_ENDDATE_FACT (255722, 7)\n",
      "real DTIME_CREDIT_UPDATE (255722, 7)\n",
      "real DIV_DELTAS (255722, 7)\n",
      "real TXT_0 (255722, 7)\n",
      "real TXT_1 (255722, 7)\n",
      "real TXT_2 (255722, 7)\n",
      "real TXT_3 (255722, 7)\n",
      "real TXT_4 (255722, 7)\n",
      "real TXT_5 (255722, 7)\n",
      "real TXT_X (255722, 7)\n",
      "real TXT_C (255722, 7)\n",
      "real TXTn_0 (255722, 7)\n",
      "real TXTn_1 (255722, 7)\n",
      "real TXTn_2 (255722, 7)\n",
      "real TXTn_3 (255722, 7)\n",
      "real TXTn_4 (255722, 7)\n",
      "real TXTn_5 (255722, 7)\n",
      "real TXTn_X (255722, 7)\n",
      "real TXTn_C (255722, 7)\n",
      "real TXT_L (255722, 7)\n",
      "real BF_0 (255722, 7)\n",
      "real BF_1 (255722, 7)\n",
      "real BF_2 (255722, 7)\n",
      "real BF_3 (255722, 7)\n",
      "real BF_4 (255722, 7)\n",
      "real BF_5 (255722, 7)\n",
      "real BF_X (255722, 7)\n",
      "real BF_C (255722, 7)\n",
      "real BF2_0 (255722, 7)\n",
      "real BF2_1 (255722, 7)\n",
      "real BF2_2 (255722, 7)\n",
      "real BF2_3 (255722, 7)\n",
      "real BF2_4 (255722, 7)\n",
      "real BF2_5 (255722, 7)\n",
      "real BF2_X (255722, 7)\n",
      "real BF2_C (255722, 7)\n",
      "real BF0_0 (255722, 7)\n",
      "real BF0_1 (255722, 7)\n",
      "real BF0_2 (255722, 7)\n",
      "real BF0_3 (255722, 7)\n",
      "real BF0_4 (255722, 7)\n",
      "real BF0_5 (255722, 7)\n",
      "real BF0_X (255722, 7)\n",
      "real BF0_C (255722, 7)\n",
      "(135155, 446) (120567, 446)\n"
     ]
    }
   ],
   "source": [
    "# 1я версия\n",
    "data_fm = [make_user_features(data_all, user_features),\n",
    "            make_cat_features(data_all, cat_features + ['TPD0'], normalize=True),\n",
    "            make_bin_features(data_all, bin_features),\n",
    "            make_real_features(data_all, real_features),\n",
    "            make_real_features(data_all, realtime_features),\n",
    "            make_real_features(data_all, txt_features + txt_features2 + txt_features0),\n",
    "            make_real_features(data_all, txt_features3)\n",
    "           ]\n",
    "\n",
    "data = make_feature_matrix(data_fm, data_all.groupby('ID').size().reset_index()['ID'].values)\n",
    "\n",
    "dataA2 = data[data.ID.isin(data_test.ID)]\n",
    "dataA = data[data.ID.isin(data_train.ID)]\n",
    "\n",
    "print (dataA.shape, dataA2.shape)\n",
    "id_test = dataA2.ID.values\n",
    "\n",
    "del dataA['ID']\n",
    "del dataA2['ID']\n",
    "\n",
    "# СОХРАНИТЬ ДАННЫЕ\n",
    "data_tmp = dataA.copy()\n",
    "data_tmp['y'] = y\n",
    "data_tmp.to_csv('my_train__.csv', index=False)\n",
    "dataA2.to_csv('my_test__.csv', index=False)\n",
    "del data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category NUM_SOURCE (255722, 5)\n",
      "category CREDIT_TYPE (255722, 7)\n",
      "category CREDIT_ACTIVE (255722, 5)\n",
      "category CREDIT_CURRENCY (255722, 4)\n",
      "category CREDIT_FACILITY (255722, 6)\n",
      "category DTIME_CREDIT_dayofweek (255722, 8)\n",
      "category DTIME_CREDIT_ENDDATE_FACT_dayofweek (238467, 8)\n",
      "category DTIME_CREDIT_UPDATE_dayofweek (255722, 8)\n",
      "category TPD0 (255722, 10)\n",
      "real CREDIT_DAY_OVERDUE (255722, 7)\n",
      "real CNT_CREDIT_PROLONG (255722, 7)\n",
      "real AMT_CREDIT_SUM (255722, 7)\n",
      "real AMT_CREDIT_SUM_DEBT (255722, 7)\n",
      "real AMT_CREDIT_SUM_LIMIT (255722, 7)\n",
      "real AMT_CREDIT_SUM_OVERDUE (255722, 7)\n",
      "real AMT_CREDIT_MAX_OVERDUE (255722, 7)\n",
      "real CREDIT_DELAY5 (255722, 7)\n",
      "real CREDIT_DELAY30 (255722, 7)\n",
      "real CREDIT_DELAY60 (255722, 7)\n",
      "real CREDIT_DELAY90 (255722, 7)\n",
      "real CREDIT_DELAY_MORE (255722, 7)\n",
      "real AMT_ANNUITY (255722, 7)\n",
      "real DOLG (255722, 7)\n",
      "real DELTA_CREDIT (255722, 7)\n",
      "real DELTA_CREDIT2 (255722, 7)\n",
      "real DELTA_ENDS (255722, 7)\n",
      "real DTIME_CREDIT (255722, 7)\n",
      "real DTIME_CREDIT_ENDDATE (255722, 7)\n",
      "real DTIME_CREDIT_ENDDATE_FACT (255722, 7)\n",
      "real DTIME_CREDIT_UPDATE (255722, 7)\n",
      "real DIV_DELTAS (255722, 7)\n",
      "real TXT_0 (255722, 7)\n",
      "real TXT_1 (255722, 7)\n",
      "real TXT_2 (255722, 7)\n",
      "real TXT_3 (255722, 7)\n",
      "real TXT_4 (255722, 7)\n",
      "real TXT_5 (255722, 7)\n",
      "real TXT_X (255722, 7)\n",
      "real TXT_C (255722, 7)\n",
      "real TXTn_0 (255722, 7)\n",
      "real TXTn_1 (255722, 7)\n",
      "real TXTn_2 (255722, 7)\n",
      "real TXTn_3 (255722, 7)\n",
      "real TXTn_4 (255722, 7)\n",
      "real TXTn_5 (255722, 7)\n",
      "real TXTn_X (255722, 7)\n",
      "real TXTn_C (255722, 7)\n",
      "real TXT_L (255722, 7)\n",
      "real BF_0 (255722, 7)\n",
      "real BF_1 (255722, 7)\n",
      "real BF_2 (255722, 7)\n",
      "real BF_3 (255722, 7)\n",
      "real BF_4 (255722, 7)\n",
      "real BF_5 (255722, 7)\n",
      "real BF_X (255722, 7)\n",
      "real BF_C (255722, 7)\n",
      "real BF2_0 (255722, 7)\n",
      "real BF2_1 (255722, 7)\n",
      "real BF2_2 (255722, 7)\n",
      "real BF2_3 (255722, 7)\n",
      "real BF2_4 (255722, 7)\n",
      "real BF2_5 (255722, 7)\n",
      "real BF2_X (255722, 7)\n",
      "real BF2_C (255722, 7)\n",
      "real BF0_0 (255722, 7)\n",
      "real BF0_1 (255722, 7)\n",
      "real BF0_2 (255722, 7)\n",
      "real BF0_3 (255722, 7)\n",
      "real BF0_4 (255722, 7)\n",
      "real BF0_5 (255722, 7)\n",
      "real BF0_X (255722, 7)\n",
      "real BF0_C (255722, 7)\n",
      "(135155, 446) (120567, 446)\n"
     ]
    }
   ],
   "source": [
    "# 2я версия\n",
    "\n",
    "data_fm = [make_user_features(data_pre, user_features),\n",
    "            make_cat_features(data_pre, cat_features + ['TPD0'], normalize=True),\n",
    "            make_bin_features(data_pre, bin_features),\n",
    "            make_real_features(data_pre, real_features),\n",
    "            make_real_features(data_pre, realtime_features),\n",
    "            make_real_features(data_pre, txt_features + txt_features2 + txt_features0),\n",
    "            make_real_features(data_pre, txt_features3)\n",
    "           ]\n",
    "\n",
    "data = make_feature_matrix(data_fm, data_all.groupby('ID').size().reset_index()['ID'].values)\n",
    "\n",
    "dataB2 = data[data.ID.isin(data_test.ID)]\n",
    "dataB = data[data.ID.isin(data_train.ID)]\n",
    "print (dataB.shape, dataB2.shape)\n",
    "\n",
    "id_test2 = dataB2.ID.values\n",
    "del dataB['ID']\n",
    "del dataB2['ID']\n",
    "\n",
    "#del data1['0c_SK_DATE_DECISION']\n",
    "#del data2['0c_SK_DATE_DECISION']\n",
    "\n",
    "# СОХРАНИТЬ ДАННЫЕ\n",
    "data_tmp = dataB.copy()\n",
    "data_tmp['y'] = y\n",
    "data_tmp.to_csv('my_train2__.csv', index=False)\n",
    "dataB2.to_csv('my_test2__.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение модели алгоритмов\n",
    "\n",
    "смесь:\n",
    "\n",
    "* 4 lgb.LGBMClassifier при разных параметрах\n",
    "* 4 xgb.XGBClassifier при разных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "class djLGB(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"смесь lgb и xgb\"\"\"\n",
    "\n",
    "    def __init__(self, seed=0, nest_lgb=1.0, nest_xgb=1.0, cbt=0.5, ss=0.5, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Инициализация\n",
    "        seed - инициализация генератора псевдослучайных чисел\n",
    "        nest_lgb, nest_xgb - сколько деревьев использовать (множитель)\n",
    "        cbt, ss - процент признаков и объектов для сэмплирования\n",
    "        alpha - коэффициент доверия XGB\n",
    "        \"\"\"\n",
    "        print('LGB + XGB')\n",
    "        self.models = [lgb.LGBMClassifier(num_leaves=2, learning_rate=0.07, n_estimators=int(1400*nest_lgb),\n",
    "                                          colsample_bytree=cbt, subsample=ss,\n",
    "                                          nthread=-1, random_state=0+seed),\n",
    "                       lgb.LGBMClassifier(num_leaves=3, learning_rate=0.07, n_estimators=int(800*nest_lgb),\n",
    "                                          colsample_bytree=cbt, subsample=ss,\n",
    "                                          nthread=-1, random_state=1+seed),\n",
    "                       lgb.LGBMClassifier(num_leaves=4, learning_rate=0.07, n_estimators=int(800*nest_lgb),\n",
    "                                          colsample_bytree=cbt, subsample=ss,\n",
    "                                          nthread=-1, random_state=2+seed),\n",
    "                       lgb.LGBMClassifier(num_leaves=5, learning_rate=0.07, n_estimators=int(600*nest_lgb),\n",
    "                                          colsample_bytree=cbt, subsample=ss,\n",
    "                                          nthread=-1, random_state=3+seed,),\n",
    "                       xgb.XGBClassifier(max_depth=1,\n",
    "                                         learning_rate=0.1,\n",
    "                                         n_estimators=int(800*nest_xgb),\n",
    "                                         subsample=ss,\n",
    "                                         colsample_bytree=cbt,\n",
    "                                         nthread=-1,\n",
    "                                         seed=0+seed),\n",
    "                       xgb.XGBClassifier(max_depth=2,\n",
    "                                         learning_rate=0.1,\n",
    "                                         n_estimators=int(400*nest_xgb),\n",
    "                                         subsample=ss,\n",
    "                                         colsample_bytree=cbt,\n",
    "                                         nthread=-1,\n",
    "                                         seed=1+seed),\n",
    "                       xgb.XGBClassifier(max_depth=3,\n",
    "                                         learning_rate=0.1,\n",
    "                                         n_estimators=int(200*nest_xgb),\n",
    "                                         subsample=ss,\n",
    "                                         colsample_bytree=cbt,\n",
    "                                         nthread=-1,\n",
    "                                         seed=2+seed),\n",
    "                       xgb.XGBClassifier(max_depth=4,\n",
    "                                         learning_rate=0.1,\n",
    "                                         n_estimators=int(200*nest_xgb),\n",
    "                                         subsample=ss,\n",
    "                                         colsample_bytree=cbt,\n",
    "                                         nthread=-1,\n",
    "                                         seed=3+seed)\n",
    "                      ]\n",
    "        self.weights = [(1-alpha)*1, (1-alpha)*1, (1-alpha)*1, (1-alpha)*0.5, alpha*0.5, alpha*1, alpha*1.5, alpha*0.5]\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        обучение\n",
    "        \"\"\"\n",
    "        for t, clf in enumerate(self.models):\n",
    "            # print ('train', t)\n",
    "            clf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        определение вероятности\n",
    "        \"\"\"\n",
    "        suma = 0.0\n",
    "        for t, clf in enumerate(self.models):\n",
    "            a = clf.predict_proba(X)[:, 1]\n",
    "            suma += (self.weights[t] * a)\n",
    "        return (suma / sum(self.weights))\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        определение вероятности\n",
    "        \"\"\"        \n",
    "        return (self.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа алгоритма\n",
    "\n",
    "усреднение 15 описанных моделей\n",
    "\n",
    "число деревьев в ансамблях взято побольше..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB + XGB\n",
      "LGB + XGB\n",
      "LGB + XGB\n",
      "LGB + XGB\n"
     ]
    }
   ],
   "source": [
    "a_A = 0.0\n",
    "a_B = 0.0\n",
    "\n",
    "N = 2 # сколько усреднять 15\n",
    "\n",
    "for t in range(N):\n",
    "    clf = djLGB(seed=2000 + 10*t, nest_lgb=1.3, nest_xgb=1.3)\n",
    "    clf.fit(dataA, y)\n",
    "    a_A += clf.predict(dataA2)\n",
    "    \n",
    "    clf = djLGB(seed=(3000 + 10*t), nest_lgb=1.3, nest_xgb=1.3)\n",
    "    clf.fit(dataB, y)\n",
    "    a_B += clf.predict(dataB2)\n",
    "    \n",
    "a = (a_A + a_B) / 2\n",
    "\n",
    "a = a - min(a)\n",
    "a = a / max(a)\n",
    "\n",
    "pd.DataFrame({'ID': id_test, 'Score': a}).to_csv('ridge_C04__.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придётся подождать, пока построятся все модели..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
